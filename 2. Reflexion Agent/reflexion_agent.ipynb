{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Reflexion Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the questions\"\"\"\n",
    "    answer: str = Field(description=\"250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the initial answer.\")\n",
    "    queries: List[str] = Field(description=\"1-3 search queries for researching improvements to address the critique of your current answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputToolsParser, PydanticToolsParser\n",
    "from langchain_core.messages import HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "llm=llm.bind_tools(tools=[AnswerQuestion],tool_choice=\"AnswerQuestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputToolsParser(return_id=True)\n",
    "pydantic_parser = PydanticToolsParser(tools=[AnswerQuestion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"\"\" \n",
    "                    You are expert researcher.\n",
    "                    Current time: {time}\n",
    "\n",
    "                    1. {first_instruction}\n",
    "                    2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "                    3. Recommend search queries to research information and improve your answer.\n",
    "                 \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\",\"Answer the user's question above using the required format.\")\n",
    "    ]\n",
    ").partial(time=lambda: datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_responder_prompt_template = actor_prompt_template.partial(first_instruction=\"Provide a detailed 200 word answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessage(\n",
    "    content=\"Write about AI-Powered SOC / autonomous soc  problem domain, \" \\\n",
    "    \"list startups that do that and raised capital.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_responder = (first_responder_prompt_template|llm|pydantic_parser)\n",
    "# first_responder = (first_responder_prompt_template|llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = first_responder.invoke(input={\"messages\":[human_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AnswerQuestion(answer='The AI-Powered Security Operations Center (SOC) or autonomous SOC is a problem domain that involves the use of Artificial Intelligence (AI) and Machine Learning (ML) to automate and enhance the capabilities of traditional SOCs. The goal of an AI-Powered SOC is to improve the efficiency and effectiveness of security operations by leveraging AI and ML to detect, respond, and prevent cyber threats in real-time. This is achieved through the use of advanced analytics, threat intelligence, and automation. Some startups that are working in this space and have raised capital include: Cyware Labs ($30 million), Securonix ($29 million), and Deep Instinct ($100 million). These startups are developing innovative solutions that utilize AI and ML to detect and respond to threats, predict and prevent breaches, and improve the overall security posture of organizations. The AI-Powered SOC market is expected to grow significantly in the coming years, driven by the increasing need for advanced security solutions that can keep pace with the evolving threat landscape. As the market continues to evolve, we can expect to see more startups emerge with innovative solutions that leverage AI and ML to enhance security operations.', reflection=Reflection(missing='The answer could be improved by providing more specific examples of how AI-Powered SOCs are being used in real-world scenarios, as well as more detailed information on the types of threats they are designed to detect and prevent. Additionally, the answer could benefit from a more in-depth analysis of the market trends and drivers that are shaping the AI-Powered SOC space.', superfluous='The answer could be improved by removing some of the more general statements about the importance of AI and ML in security, and instead focusing more on the specific details of AI-Powered SOCs and the startups that are working in this space.'), queries=['AI-Powered SOC startups', 'autonomous SOC market trends', 'AI-Powered SOC use cases'])]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response)\n",
    "# pprint(response[0].answer)\n",
    "# pprint(response[0].reflection)\n",
    "# pprint(response[0].queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"Revise your original answer to your question.\"\n",
    "    references: List[str] = Field(description=\"Citations motivating your updated answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"\n",
    "    Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisor = actor_prompt_template.partial(first_instruction=revise_instructions) | llm.bind_tools(tools=[ReviseAnswer],tool_choice=\"ReviseAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tool Executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.messages import AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchAPIWrapper()\n",
    "tavily_tool = TavilySearchResults(api_wrapper=search,max_results=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_queries(search_queries: list[str], **kwargs):\n",
    "    \"\"\"Run the generated queries.\"\"\"\n",
    "    return tavily_tool.batch([{\"query\": query} for query in search_queries])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_node = ToolNode([run_queries])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_response = first_responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaining_tool = first_responder|tool_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Last message is not an AIMessage",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# search_result = run_queries(response[0].queries)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m search_result = \u001b[43mchaining_tool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m[\u001b[49m\u001b[43mhuman_message\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langchain_core/runnables/base.py:3047\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3045\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m   3046\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m                 \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3049\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/utils/runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:235\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    226\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     store: Optional[BaseStore],\n\u001b[32m    234\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     tool_calls, input_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    237\u001b[39m     input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:446\u001b[39m, in \u001b[36mToolNode._parse_input\u001b[39m\u001b[34m(self, input, store)\u001b[39m\n\u001b[32m    443\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo message found in input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, AIMessage):\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLast message is not an AIMessage\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    448\u001b[39m tool_calls = [\n\u001b[32m    449\u001b[39m     \u001b[38;5;28mself\u001b[39m.inject_tool_args(call, \u001b[38;5;28minput\u001b[39m, store) \u001b[38;5;28;01mfor\u001b[39;00m call \u001b[38;5;129;01min\u001b[39;00m message.tool_calls\n\u001b[32m    450\u001b[39m ]\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tool_calls, input_type\n",
      "\u001b[31mValueError\u001b[39m: Last message is not an AIMessage"
     ]
    }
   ],
   "source": [
    "# search_result = run_queries(response[0].queries)\n",
    "search_result = chaining_tool.invoke(input={\"messages\":[human_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No message found in input",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m tool_response=\u001b[43mtool_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_pass_in_tool\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgenerations\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/utils/runnable.py:371\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    370\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m         ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:235\u001b[39m, in \u001b[36mToolNode._func\u001b[39m\u001b[34m(self, input, config, store)\u001b[39m\n\u001b[32m    224\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_func\u001b[39m(\n\u001b[32m    225\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    226\u001b[39m     \u001b[38;5;28minput\u001b[39m: Union[\n\u001b[32m   (...)\u001b[39m\u001b[32m    233\u001b[39m     store: Optional[BaseStore],\n\u001b[32m    234\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     tool_calls, input_type = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m     config_list = get_config_list(config, \u001b[38;5;28mlen\u001b[39m(tool_calls))\n\u001b[32m    237\u001b[39m     input_types = [input_type] * \u001b[38;5;28mlen\u001b[39m(tool_calls)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/pypoetry/virtualenvs/langraph-kxc4EU_1-py3.12/lib/python3.12/site-packages/langgraph/prebuilt/tool_node.py:443\u001b[39m, in \u001b[36mToolNode._parse_input\u001b[39m\u001b[34m(self, input, store)\u001b[39m\n\u001b[32m    441\u001b[39m     message = messages[-\u001b[32m1\u001b[39m]\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m443\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo message found in input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(message, AIMessage):\n\u001b[32m    446\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mLast message is not an AIMessage\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: No message found in input"
     ]
    }
   ],
   "source": [
    "tool_response=tool_node.invoke(to_pass_in_tool['generations'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph-kxc4EU_1-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
