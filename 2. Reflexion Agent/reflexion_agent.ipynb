{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Reflexion Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actor Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reflection(BaseModel):\n",
    "    missing: str = Field(description=\"Critique of what is missing.\")\n",
    "    superfluous: str = Field(description=\"Critique of what is superfluous.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerQuestion(BaseModel):\n",
    "    \"\"\"Answer the questions\"\"\"\n",
    "    answer: str = Field(description=\"250 word detailed answer to the question.\")\n",
    "    reflection: Reflection = Field(description=\"Your reflection on the initial answer.\")\n",
    "    queries: List[str] = Field(description=\"1-3 search queries for researching improvements to address the critique of your current answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from datetime import datetime\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import JsonOutputToolsParser, PydanticToolsParser\n",
    "from langchain_core.messages import HumanMessage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "llm = ChatGroq(model=\"llama-3.3-70b-versatile\")\n",
    "llm=llm.bind_tools(tools=[AnswerQuestion],tool_choice=\"AnswerQuestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7f4b0ffa6510>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7f4b0ffa7290>, model_name='llama-3.3-70b-versatile', model_kwargs={}, groq_api_key=SecretStr('**********')), kwargs={'tools': [{'type': 'function', 'function': {'name': 'AnswerQuestion', 'description': 'Answer the questions', 'parameters': {'properties': {'answer': {'description': '250 word detailed answer to the question.', 'type': 'string'}, 'reflection': {'properties': {'missing': {'description': 'Critique of what is missing.', 'type': 'string'}, 'superfluous': {'description': 'Critique of what is superfluous.', 'type': 'string'}}, 'required': ['missing', 'superfluous'], 'type': 'object'}, 'queries': {'description': '1-3 search queries for researching improvements to address the critique of your current answer.', 'items': {'type': 'string'}, 'type': 'array'}}, 'required': ['answer', 'reflection', 'queries'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'AnswerQuestion'}}}, config={}, config_factories=[])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_parser = JsonOutputToolsParser(return_id=True)\n",
    "pydantic_parser = PydanticToolsParser(tools=[AnswerQuestion])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticToolsParser(tools=[<class '__main__.AnswerQuestion'>])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"\"\" \n",
    "                    You are expert researcher.\n",
    "                    Current time: {time}\n",
    "\n",
    "                    1. {first_instruction}\n",
    "                    2. Reflect and critique your answer. Be severe to maximize improvement.\n",
    "                    3. Recommend search queries to research information and improve your answer.\n",
    "                 \"\"\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\",\"Answer the user's question above using the required format.\")\n",
    "    ]\n",
    ").partial(time=lambda: datetime.now().isoformat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_responder_prompt_template = actor_prompt_template.partial(first_instruction=\"Provide a detailed 200 word answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_message = HumanMessage(\n",
    "    content=\"Write about AI-Powered SOC / autonomous soc  problem domain, \" \\\n",
    "    \"list startups that do that and raised capital.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (first_responder_prompt_template|llm|pydantic_parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke(input={\"messages\":[human_message]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('An AI-Powered Security Operations Center (SOC) utilizes artificial '\n",
      " 'intelligence and machine learning to enhance the efficiency and '\n",
      " 'effectiveness of security operations. The primary goal is to identify, '\n",
      " 'analyze, and respond to security threats in real-time, minimizing the risk '\n",
      " 'of breaches and attacks. Autonomous SOC solutions aim to automate many of '\n",
      " 'the manual tasks associated with security monitoring, incident response, and '\n",
      " 'threat hunting, allowing human security analysts to focus on higher-level '\n",
      " 'tasks that require expertise and judgment. Startups in this domain, such as '\n",
      " 'Cybereason, Securonix, and Deep Instinct, have raised significant capital to '\n",
      " 'develop and deploy AI-powered SOC solutions. For instance, Cybereason raised '\n",
      " '$350 million in Series F funding, while Securonix raised $1 billion in '\n",
      " 'Series F funding. Other notable startups include JASK, which was acquired by '\n",
      " 'Sumo Logic, and Cardinality, which offers an autonomous threat hunting '\n",
      " 'platform. These companies are pioneering the use of AI and machine learning '\n",
      " 'in security operations, enabling organizations to stay ahead of emerging '\n",
      " 'threats and improve their overall security posture.')\n",
      "Reflection(missing='The answer could benefit from more specific examples of how AI-Powered SOC solutions improve security operations, as well as a more detailed analysis of the market trends and challenges in this domain.', superfluous='The answer does not require a detailed explanation of the basics of AI and machine learning, and could focus more on the specific applications and innovations in the AI-Powered SOC space.')\n",
      "['AI-Powered SOC startups',\n",
      " 'autonomous security operations center',\n",
      " 'AI-powered threat detection']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(response[0].answer)\n",
    "pprint(response[0].reflection)\n",
    "pprint(response[0].queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReviseAnswer(AnswerQuestion):\n",
    "    \"Revise your original answer to your question.\"\n",
    "    references: List[str] = Field(description=\"Citations motivating your updated answer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "revise_instructions = \"\"\"\n",
    "    Revise your previous answer using the new information.\n",
    "    - You should use the previous critique to add important information to your answer.\n",
    "        - You MUST include numerical citations in your revised answer to ensure it can be verified.\n",
    "        - Add a \"References\" section to the bottom of your answer (which does not count towards the word limit). In form of:\n",
    "            - [1] https://example.com\n",
    "            - [2] https://example.com\n",
    "    - You should use the previous critique to remove superfluous information from your answer and make SURE it is not more than 250 words.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisor = actor_prompt_template.partial(first_instruction=revise_instructions) | llm.bind_tools(tools=[ReviseAnswer],tool_choice=\"ReviseAnswer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langraph-kxc4EU_1-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
